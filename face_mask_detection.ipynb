{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_mask_detection.ipynb",
      "provenance": [],
      "mount_file_id": "1kG9yFBg86jEBVPzJedIcDvfToEIKPXZx",
      "authorship_tag": "ABX9TyPSaDQouH02v5JwQb05RTO6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athirajoshy/firstrepository/blob/master/face_mask_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlEhz2zSWs6t"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRkNOjrTdjUk"
      },
      "source": [
        "from tensorflow.keras.layers import Input,Flatten,Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np\n",
        "from glob import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVzLt6x_eFjA",
        "outputId": "aac1669b-d23a-473e-b5eb-5ba2ef12291f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzHrj9RyfAuO"
      },
      "source": [
        "image_size=[224,224]\n",
        "train_data_path='/content/drive/MyDrive/dataset_train'\n",
        "valid_data_path='/content/drive/MyDrive/test_dataset_mask'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9rAWKp0j2rv",
        "outputId": "2707d92b-685c-4e2e-e370-b33de32a8dbf"
      },
      "source": [
        "inception=InceptionV3(input_shape=image_size+[3],weights='imagenet',include_top=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtZlRNPSkn5F"
      },
      "source": [
        "for i in inception.layers:\n",
        "  i.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6NPSVp301Be",
        "outputId": "a52e5e39-04c3-4848-b26f-7d88537fa7b9"
      },
      "source": [
        "folders = glob('/content/drive/My Drive/dataset_train/*')\n",
        "len(folders)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkkxZqCi1Fr4"
      },
      "source": [
        "x = Flatten()(inception.output)#output from inception is flattened"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgd1VA8O1ie0"
      },
      "source": [
        "prediction = Dense(len(folders), activation='sigmoid')(x)\n",
        "\n",
        "# create a model object\n",
        "model = Model(inputs=inception.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ-OoH8V2skP"
      },
      "source": [
        "model.compile(\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  optimizer='Adam',\n",
        "  metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opoLJummfOgU"
      },
      "source": [
        "#data augmentation\n",
        "training_data=ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_7xbltAgB7d",
        "outputId": "f72aa9eb-a86c-47d7-9535-f479dd66eb93"
      },
      "source": [
        "training_set = training_data.flow_from_directory('/content/drive/My Drive/dataset_train',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3834 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1Kf1c_EgHQM",
        "outputId": "7cabd015-dea8-4512-fa4a-2555e1a5336e"
      },
      "source": [
        "training_set.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'with_mask': 0, 'without_mask': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4chtPsENhKi4"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWzSIao4hMCn",
        "outputId": "ad1ebf48-ea7d-4ce5-870c-a18b28944d2a"
      },
      "source": [
        "testing_data = test_datagen.flow_from_directory('/content/drive/My Drive/test_dataset_mask',\n",
        "                                                 target_size = (224, 224),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 452 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rTTI4cT4lLe",
        "outputId": "16a0e8e7-30e0-4fc4-b6e1-02183f5de58a"
      },
      "source": [
        "r = model.fit_generator(\n",
        "  training_set,\n",
        "  validation_data=testing_data,\n",
        "  epochs=10,\n",
        "  steps_per_epoch=len(training_set),\n",
        "  validation_steps=len(testing_data)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            " 31/120 [======>.......................] - ETA: 17:08 - loss: 1.9146 - accuracy: 0.8151"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "120/120 [==============================] - ETA: 0s - loss: 0.8974 - accuracy: 0.9173 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "120/120 [==============================] - 1571s 13s/step - loss: 0.8929 - accuracy: 0.9177 - val_loss: 0.9199 - val_accuracy: 0.9403\n",
            "Epoch 2/10\n",
            "120/120 [==============================] - 496s 4s/step - loss: 0.0596 - accuracy: 0.9947 - val_loss: 0.7259 - val_accuracy: 0.9358\n",
            "Epoch 3/10\n",
            "120/120 [==============================] - 499s 4s/step - loss: 0.0427 - accuracy: 0.9957 - val_loss: 2.0644 - val_accuracy: 0.8894\n",
            "Epoch 4/10\n",
            "120/120 [==============================] - 501s 4s/step - loss: 0.0482 - accuracy: 0.9953 - val_loss: 1.1975 - val_accuracy: 0.9159\n",
            "Epoch 5/10\n",
            "120/120 [==============================] - 501s 4s/step - loss: 0.0668 - accuracy: 0.9954 - val_loss: 2.0947 - val_accuracy: 0.9093\n",
            "Epoch 6/10\n",
            "120/120 [==============================] - 497s 4s/step - loss: 0.0553 - accuracy: 0.9958 - val_loss: 1.6303 - val_accuracy: 0.9226\n",
            "Epoch 7/10\n",
            "120/120 [==============================] - 498s 4s/step - loss: 0.0321 - accuracy: 0.9973 - val_loss: 2.1423 - val_accuracy: 0.9137\n",
            "Epoch 8/10\n",
            "120/120 [==============================] - 493s 4s/step - loss: 0.0788 - accuracy: 0.9947 - val_loss: 3.8001 - val_accuracy: 0.8783\n",
            "Epoch 9/10\n",
            "120/120 [==============================] - 494s 4s/step - loss: 0.0843 - accuracy: 0.9956 - val_loss: 1.8031 - val_accuracy: 0.9336\n",
            "Epoch 10/10\n",
            "120/120 [==============================] - 493s 4s/step - loss: 0.0241 - accuracy: 0.9980 - val_loss: 1.9228 - val_accuracy: 0.9071\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzEa72b29jo7"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/MyDrive/models/model_mask_inception.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}